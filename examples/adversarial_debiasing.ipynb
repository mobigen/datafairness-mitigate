{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Tensorflow Version"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "1.15.0"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "# Import Packages\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from utils import datasets\n",
    "from metric import DatasetMetric\n",
    "from metric import ClassificationMetric\n",
    "from algorithm.adversarial_debiasing import AdversarialDebiasing\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "display(Markdown('#### Tensorflow Version'))\n",
    "display(Markdown(tf.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-1. Load & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Data: 0 rows removed.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Basic Statistics of DataFrame"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (48842, 19)\n",
      "               race           sex  Age (decade)=10  Age (decade)=20  \\\n",
      "count  48842.000000  48842.000000     48842.000000     48842.000000   \n",
      "mean       0.855043      0.668482         0.051390         0.245793   \n",
      "std        0.352061      0.470764         0.220795         0.430561   \n",
      "min        0.000000      0.000000         0.000000         0.000000   \n",
      "25%        1.000000      0.000000         0.000000         0.000000   \n",
      "50%        1.000000      1.000000         0.000000         0.000000   \n",
      "75%        1.000000      1.000000         0.000000         0.000000   \n",
      "max        1.000000      1.000000         1.000000         1.000000   \n",
      "\n",
      "       Age (decade)=30  Age (decade)=40  Age (decade)=50  Age (decade)=60  \\\n",
      "count     48842.000000     48842.000000     48842.000000     48842.000000   \n",
      "mean          0.264711         0.219565         0.135519         0.062528   \n",
      "std           0.441184         0.413956         0.342280         0.242115   \n",
      "min           0.000000         0.000000         0.000000         0.000000   \n",
      "25%           0.000000         0.000000         0.000000         0.000000   \n",
      "50%           0.000000         0.000000         0.000000         0.000000   \n",
      "75%           1.000000         0.000000         0.000000         0.000000   \n",
      "max           1.000000         1.000000         1.000000         1.000000   \n",
      "\n",
      "       Age (decade)=>=70  Education Years=6  Education Years=7  \\\n",
      "count       48842.000000       48842.000000       48842.000000   \n",
      "mean            0.020495           0.028439           0.037099   \n",
      "std             0.141686           0.166224           0.189007   \n",
      "min             0.000000           0.000000           0.000000   \n",
      "25%             0.000000           0.000000           0.000000   \n",
      "50%             0.000000           0.000000           0.000000   \n",
      "75%             0.000000           0.000000           0.000000   \n",
      "max             1.000000           1.000000           1.000000   \n",
      "\n",
      "       Education Years=8  Education Years=9  Education Years=10  \\\n",
      "count       48842.000000       48842.000000        48842.000000   \n",
      "mean            0.013452           0.323164            0.222718   \n",
      "std             0.115199           0.467690            0.416075   \n",
      "min             0.000000           0.000000            0.000000   \n",
      "25%             0.000000           0.000000            0.000000   \n",
      "50%             0.000000           0.000000            0.000000   \n",
      "75%             0.000000           1.000000            0.000000   \n",
      "max             1.000000           1.000000            1.000000   \n",
      "\n",
      "       Education Years=11  Education Years=12  Education Years=<6  \\\n",
      "count        48842.000000        48842.000000        48842.000000   \n",
      "mean             0.042197            0.032779            0.052209   \n",
      "std              0.201041            0.178060            0.222451   \n",
      "min              0.000000            0.000000            0.000000   \n",
      "25%              0.000000            0.000000            0.000000   \n",
      "50%              0.000000            0.000000            0.000000   \n",
      "75%              0.000000            0.000000            0.000000   \n",
      "max              1.000000            1.000000            1.000000   \n",
      "\n",
      "       Education Years=>12  \n",
      "count         48842.000000  \n",
      "mean              0.247942  \n",
      "std               0.431823  \n",
      "min               0.000000  \n",
      "25%               0.000000  \n",
      "50%               0.000000  \n",
      "75%               0.000000  \n",
      "max               1.000000  \n"
     ]
    }
   ],
   "source": [
    "# Set Columns and Protected Atrributes\n",
    "# 18 Features including 2 Protected Attributes and 1 Label\n",
    "protected_attribute_names = ['sex', 'race']\n",
    "privileged_classes = [['Male'], ['White']]\n",
    "label_name = 'income-per-year'\n",
    "one_hot_features = ['Age (decade)', 'Education Years']\n",
    "\n",
    "# Load Test Dataset & Preprocess\n",
    "df_orig = datasets.get_adults_df()\n",
    "df_orig = datasets.preprocess_df(df_orig,\n",
    "                            protected_attribute_names, privileged_classes,\n",
    "                            label_name, ['>50K', '>50K.'],\n",
    "                            one_hot_column_names=one_hot_features)\n",
    "\n",
    "display(Markdown('#### Basic Statistics of DataFrame'))\n",
    "datasets.describe_df(df_orig, detail=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-2. Train Test Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Trainset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (34189, 19)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Testset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (14653, 19)\n"
     ]
    }
   ],
   "source": [
    "# Split Dataset to train:test=7:3\n",
    "df_orig_train, df_orig_test = datasets.split_df(df_orig)\n",
    "\n",
    "display(Markdown('#### Trainset'))\n",
    "datasets.describe_df(df_orig_train)\n",
    "display(Markdown('#### Testset'))\n",
    "datasets.describe_df(df_orig_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-3. Fairness Metric Origin Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 자체에 대한 Metric\n",
    "dataset_metric_train_without_debias = DatasetMetric(df_orig_train, 'sex', label_name)\n",
    "dataset_metric_test_without_debias = DatasetMetric(df_orig_test, 'sex', label_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Original Dataset Metric"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### - Base Rate"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Unprivileged, Privileged Group 에서 각각 Positive가 차지하는 비율"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set, Unprivileged Group: 0.107304\n",
      " Test Set, Unprivileged Group: 0.113743\n",
      "Train Set, Privileged Group: 0.304927\n",
      " Test Set, Privileged Group: 0.301046\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### - Mean Difference"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Unprivileged, Privileged Group 간 Base Rate의 차"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set: Mean Difference between Unprivileged and Privileged Group = -0.197623\n",
      " Test Set: Mean Difference between Unprivileged and Privileged Group = -0.187302\n"
     ]
    }
   ],
   "source": [
    "display(Markdown('#### Original Dataset Metric'))\n",
    "\n",
    "display(Markdown('#### - Base Rate'))\n",
    "display(Markdown('Unprivileged, Privileged Group 에서 각각 Positive가 차지하는 비율'))\n",
    "print('Train Set, Unprivileged Group: %f'%dataset_metric_train_without_debias.base_rate(privileged=False))\n",
    "print(' Test Set, Unprivileged Group: %f'%dataset_metric_test_without_debias.base_rate(privileged=False))\n",
    "print('Train Set, Privileged Group: %f'%dataset_metric_train_without_debias.base_rate(privileged=True))\n",
    "print(' Test Set, Privileged Group: %f'%dataset_metric_test_without_debias.base_rate(privileged=True))\n",
    "\n",
    "display(Markdown('#### - Mean Difference'))\n",
    "display(Markdown('Unprivileged, Privileged Group 간 Base Rate의 차'))\n",
    "print('Train Set: Mean Difference between Unprivileged and Privileged Group = %f'%dataset_metric_train_without_debias.mean_difference())\n",
    "print(' Test Set: Mean Difference between Unprivileged and Privileged Group = %f'%dataset_metric_test_without_debias.mean_difference())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Learn Classifier with Adversarial Debiasing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1. Model without debiasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debiasing을 하지 않는 Plain Model\n",
    "privileged_groups = [{'sex': 1}]\n",
    "unprivileged_groups = [{'sex': 0}]\n",
    "\n",
    "sess = tf.Session()\n",
    "plain_model = AdversarialDebiasing(unprivileged_groups, privileged_groups, 'plain_classifier', sess, debias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/bsw/tools/jupyter-server-conda/data/DataFairness/datafairness-mitigate/algorithm/adversarial_debiasing.py:124: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/bsw/tools/jupyter-server-conda/data/DataFairness/datafairness-mitigate/algorithm/adversarial_debiasing.py:126: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/bsw/tools/jupyter-server-conda/data/DataFairness/datafairness-mitigate/algorithm/adversarial_debiasing.py:64: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /home/bsw/tools/jupyter-server-conda/data/DataFairness/datafairness-mitigate/algorithm/adversarial_debiasing.py:69: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/bsw/miniconda3/envs/tf1_gpu/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/bsw/tools/jupyter-server-conda/data/DataFairness/datafairness-mitigate/algorithm/adversarial_debiasing.py:144: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/bsw/tools/jupyter-server-conda/data/DataFairness/datafairness-mitigate/algorithm/adversarial_debiasing.py:146: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/bsw/tools/jupyter-server-conda/data/DataFairness/datafairness-mitigate/algorithm/adversarial_debiasing.py:150: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/bsw/tools/jupyter-server-conda/data/DataFairness/datafairness-mitigate/algorithm/adversarial_debiasing.py:171: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/bsw/tools/jupyter-server-conda/data/DataFairness/datafairness-mitigate/algorithm/adversarial_debiasing.py:172: The name tf.local_variables_initializer is deprecated. Please use tf.compat.v1.local_variables_initializer instead.\n",
      "\n",
      "epoch 0; iter: 0; batch classifier loss: 0.693265\n",
      "epoch 0; iter: 200; batch classifier loss: 0.421329\n",
      "epoch 1; iter: 0; batch classifier loss: 0.423698\n",
      "epoch 1; iter: 200; batch classifier loss: 0.480042\n",
      "epoch 2; iter: 0; batch classifier loss: 0.420901\n",
      "epoch 2; iter: 200; batch classifier loss: 0.521556\n",
      "epoch 3; iter: 0; batch classifier loss: 0.427451\n",
      "epoch 3; iter: 200; batch classifier loss: 0.352460\n",
      "epoch 4; iter: 0; batch classifier loss: 0.439303\n",
      "epoch 4; iter: 200; batch classifier loss: 0.377346\n",
      "epoch 5; iter: 0; batch classifier loss: 0.512787\n",
      "epoch 5; iter: 200; batch classifier loss: 0.428861\n",
      "epoch 6; iter: 0; batch classifier loss: 0.403127\n",
      "epoch 6; iter: 200; batch classifier loss: 0.430678\n",
      "epoch 7; iter: 0; batch classifier loss: 0.484325\n",
      "epoch 7; iter: 200; batch classifier loss: 0.461740\n",
      "epoch 8; iter: 0; batch classifier loss: 0.376905\n",
      "epoch 8; iter: 200; batch classifier loss: 0.434637\n",
      "epoch 9; iter: 0; batch classifier loss: 0.591316\n",
      "epoch 9; iter: 200; batch classifier loss: 0.392094\n",
      "epoch 10; iter: 0; batch classifier loss: 0.446225\n",
      "epoch 10; iter: 200; batch classifier loss: 0.416551\n",
      "epoch 11; iter: 0; batch classifier loss: 0.429562\n",
      "epoch 11; iter: 200; batch classifier loss: 0.478498\n",
      "epoch 12; iter: 0; batch classifier loss: 0.447068\n",
      "epoch 12; iter: 200; batch classifier loss: 0.379430\n",
      "epoch 13; iter: 0; batch classifier loss: 0.381226\n",
      "epoch 13; iter: 200; batch classifier loss: 0.383441\n",
      "epoch 14; iter: 0; batch classifier loss: 0.464608\n",
      "epoch 14; iter: 200; batch classifier loss: 0.425109\n",
      "epoch 15; iter: 0; batch classifier loss: 0.436778\n",
      "epoch 15; iter: 200; batch classifier loss: 0.387356\n",
      "epoch 16; iter: 0; batch classifier loss: 0.401310\n",
      "epoch 16; iter: 200; batch classifier loss: 0.447489\n",
      "epoch 17; iter: 0; batch classifier loss: 0.416380\n",
      "epoch 17; iter: 200; batch classifier loss: 0.522961\n",
      "epoch 18; iter: 0; batch classifier loss: 0.477358\n",
      "epoch 18; iter: 200; batch classifier loss: 0.485139\n",
      "epoch 19; iter: 0; batch classifier loss: 0.454359\n",
      "epoch 19; iter: 200; batch classifier loss: 0.373887\n",
      "epoch 20; iter: 0; batch classifier loss: 0.368865\n",
      "epoch 20; iter: 200; batch classifier loss: 0.439513\n",
      "epoch 21; iter: 0; batch classifier loss: 0.508704\n",
      "epoch 21; iter: 200; batch classifier loss: 0.456646\n",
      "epoch 22; iter: 0; batch classifier loss: 0.425705\n",
      "epoch 22; iter: 200; batch classifier loss: 0.462738\n",
      "epoch 23; iter: 0; batch classifier loss: 0.335415\n",
      "epoch 23; iter: 200; batch classifier loss: 0.381315\n",
      "epoch 24; iter: 0; batch classifier loss: 0.388767\n",
      "epoch 24; iter: 200; batch classifier loss: 0.492382\n",
      "epoch 25; iter: 0; batch classifier loss: 0.396494\n",
      "epoch 25; iter: 200; batch classifier loss: 0.431402\n",
      "epoch 26; iter: 0; batch classifier loss: 0.440600\n",
      "epoch 26; iter: 200; batch classifier loss: 0.373555\n",
      "epoch 27; iter: 0; batch classifier loss: 0.457393\n",
      "epoch 27; iter: 200; batch classifier loss: 0.451300\n",
      "epoch 28; iter: 0; batch classifier loss: 0.418248\n",
      "epoch 28; iter: 200; batch classifier loss: 0.386020\n",
      "epoch 29; iter: 0; batch classifier loss: 0.440287\n",
      "epoch 29; iter: 200; batch classifier loss: 0.379945\n",
      "epoch 30; iter: 0; batch classifier loss: 0.382904\n",
      "epoch 30; iter: 200; batch classifier loss: 0.390918\n",
      "epoch 31; iter: 0; batch classifier loss: 0.442364\n",
      "epoch 31; iter: 200; batch classifier loss: 0.527060\n",
      "epoch 32; iter: 0; batch classifier loss: 0.501147\n",
      "epoch 32; iter: 200; batch classifier loss: 0.436175\n",
      "epoch 33; iter: 0; batch classifier loss: 0.459517\n",
      "epoch 33; iter: 200; batch classifier loss: 0.384460\n",
      "epoch 34; iter: 0; batch classifier loss: 0.440654\n",
      "epoch 34; iter: 200; batch classifier loss: 0.382845\n",
      "epoch 35; iter: 0; batch classifier loss: 0.421280\n",
      "epoch 35; iter: 200; batch classifier loss: 0.443725\n",
      "epoch 36; iter: 0; batch classifier loss: 0.452406\n",
      "epoch 36; iter: 200; batch classifier loss: 0.432761\n",
      "epoch 37; iter: 0; batch classifier loss: 0.445378\n",
      "epoch 37; iter: 200; batch classifier loss: 0.365240\n",
      "epoch 38; iter: 0; batch classifier loss: 0.399817\n",
      "epoch 38; iter: 200; batch classifier loss: 0.433031\n",
      "epoch 39; iter: 0; batch classifier loss: 0.508377\n",
      "epoch 39; iter: 200; batch classifier loss: 0.429703\n",
      "epoch 40; iter: 0; batch classifier loss: 0.529655\n",
      "epoch 40; iter: 200; batch classifier loss: 0.409478\n",
      "epoch 41; iter: 0; batch classifier loss: 0.375515\n",
      "epoch 41; iter: 200; batch classifier loss: 0.424489\n",
      "epoch 42; iter: 0; batch classifier loss: 0.452650\n",
      "epoch 42; iter: 200; batch classifier loss: 0.382627\n",
      "epoch 43; iter: 0; batch classifier loss: 0.313719\n",
      "epoch 43; iter: 200; batch classifier loss: 0.424960\n",
      "epoch 44; iter: 0; batch classifier loss: 0.388243\n",
      "epoch 44; iter: 200; batch classifier loss: 0.401312\n",
      "epoch 45; iter: 0; batch classifier loss: 0.414096\n",
      "epoch 45; iter: 200; batch classifier loss: 0.482657\n",
      "epoch 46; iter: 0; batch classifier loss: 0.343218\n",
      "epoch 46; iter: 200; batch classifier loss: 0.429051\n",
      "epoch 47; iter: 0; batch classifier loss: 0.353130\n",
      "epoch 47; iter: 200; batch classifier loss: 0.471572\n",
      "epoch 48; iter: 0; batch classifier loss: 0.446589\n",
      "epoch 48; iter: 200; batch classifier loss: 0.389451\n",
      "epoch 49; iter: 0; batch classifier loss: 0.428343\n",
      "epoch 49; iter: 200; batch classifier loss: 0.440777\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<algorithm.adversarial_debiasing.AdversarialDebiasing at 0x7faffa7e33d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plain_model.fit(df_orig_train, protected_attribute_names, label_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습된 Plain Model을 Test Data에 적용\n",
    "df_pred_train_nodebiased = plain_model.predict(df_orig_train, label_name)\n",
    "df_pred_test_nodebiased = plain_model.predict(df_orig_test, label_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2. Model with debiasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debiasing을 수행하는 Debiased Model\n",
    "sess.close()\n",
    "tf.reset_default_graph()\n",
    "sess = tf.Session()\n",
    "\n",
    "debiased_model = AdversarialDebiasing(unprivileged_groups, privileged_groups, 'debiased_classifier', sess, debias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.729280; batch adversarial loss: 0.712491\n",
      "epoch 0; iter: 200; batch classifier loss: 0.475521; batch adversarial loss: 0.663415\n",
      "epoch 1; iter: 0; batch classifier loss: 0.500114; batch adversarial loss: 0.660279\n",
      "epoch 1; iter: 200; batch classifier loss: 0.571726; batch adversarial loss: 0.641949\n",
      "epoch 2; iter: 0; batch classifier loss: 0.479941; batch adversarial loss: 0.643456\n",
      "epoch 2; iter: 200; batch classifier loss: 0.390424; batch adversarial loss: 0.598190\n",
      "epoch 3; iter: 0; batch classifier loss: 0.482570; batch adversarial loss: 0.656016\n",
      "epoch 3; iter: 200; batch classifier loss: 0.511787; batch adversarial loss: 0.584736\n",
      "epoch 4; iter: 0; batch classifier loss: 0.437538; batch adversarial loss: 0.643871\n",
      "epoch 4; iter: 200; batch classifier loss: 0.434313; batch adversarial loss: 0.593502\n",
      "epoch 5; iter: 0; batch classifier loss: 0.458726; batch adversarial loss: 0.636523\n",
      "epoch 5; iter: 200; batch classifier loss: 0.495993; batch adversarial loss: 0.587677\n",
      "epoch 6; iter: 0; batch classifier loss: 0.445581; batch adversarial loss: 0.635203\n",
      "epoch 6; iter: 200; batch classifier loss: 0.432746; batch adversarial loss: 0.618818\n",
      "epoch 7; iter: 0; batch classifier loss: 0.520653; batch adversarial loss: 0.655999\n",
      "epoch 7; iter: 200; batch classifier loss: 0.372552; batch adversarial loss: 0.640480\n",
      "epoch 8; iter: 0; batch classifier loss: 0.390587; batch adversarial loss: 0.567322\n",
      "epoch 8; iter: 200; batch classifier loss: 0.377714; batch adversarial loss: 0.633170\n",
      "epoch 9; iter: 0; batch classifier loss: 0.400376; batch adversarial loss: 0.600627\n",
      "epoch 9; iter: 200; batch classifier loss: 0.467054; batch adversarial loss: 0.603790\n",
      "epoch 10; iter: 0; batch classifier loss: 0.422215; batch adversarial loss: 0.635107\n",
      "epoch 10; iter: 200; batch classifier loss: 0.418192; batch adversarial loss: 0.651953\n",
      "epoch 11; iter: 0; batch classifier loss: 0.451968; batch adversarial loss: 0.640652\n",
      "epoch 11; iter: 200; batch classifier loss: 0.418683; batch adversarial loss: 0.598557\n",
      "epoch 12; iter: 0; batch classifier loss: 0.414992; batch adversarial loss: 0.576675\n",
      "epoch 12; iter: 200; batch classifier loss: 0.391490; batch adversarial loss: 0.596281\n",
      "epoch 13; iter: 0; batch classifier loss: 0.417443; batch adversarial loss: 0.578880\n",
      "epoch 13; iter: 200; batch classifier loss: 0.489337; batch adversarial loss: 0.541697\n",
      "epoch 14; iter: 0; batch classifier loss: 0.441066; batch adversarial loss: 0.583242\n",
      "epoch 14; iter: 200; batch classifier loss: 0.432410; batch adversarial loss: 0.652959\n",
      "epoch 15; iter: 0; batch classifier loss: 0.465961; batch adversarial loss: 0.640738\n",
      "epoch 15; iter: 200; batch classifier loss: 0.424790; batch adversarial loss: 0.594172\n",
      "epoch 16; iter: 0; batch classifier loss: 0.413429; batch adversarial loss: 0.708552\n",
      "epoch 16; iter: 200; batch classifier loss: 0.369849; batch adversarial loss: 0.630233\n",
      "epoch 17; iter: 0; batch classifier loss: 0.508778; batch adversarial loss: 0.587391\n",
      "epoch 17; iter: 200; batch classifier loss: 0.376754; batch adversarial loss: 0.646611\n",
      "epoch 18; iter: 0; batch classifier loss: 0.396949; batch adversarial loss: 0.634776\n",
      "epoch 18; iter: 200; batch classifier loss: 0.421320; batch adversarial loss: 0.593729\n",
      "epoch 19; iter: 0; batch classifier loss: 0.476250; batch adversarial loss: 0.642336\n",
      "epoch 19; iter: 200; batch classifier loss: 0.485295; batch adversarial loss: 0.649962\n",
      "epoch 20; iter: 0; batch classifier loss: 0.426798; batch adversarial loss: 0.649517\n",
      "epoch 20; iter: 200; batch classifier loss: 0.369818; batch adversarial loss: 0.610829\n",
      "epoch 21; iter: 0; batch classifier loss: 0.512990; batch adversarial loss: 0.610285\n",
      "epoch 21; iter: 200; batch classifier loss: 0.473868; batch adversarial loss: 0.586439\n",
      "epoch 22; iter: 0; batch classifier loss: 0.438923; batch adversarial loss: 0.646808\n",
      "epoch 22; iter: 200; batch classifier loss: 0.390039; batch adversarial loss: 0.670157\n",
      "epoch 23; iter: 0; batch classifier loss: 0.443052; batch adversarial loss: 0.597807\n",
      "epoch 23; iter: 200; batch classifier loss: 0.435065; batch adversarial loss: 0.580569\n",
      "epoch 24; iter: 0; batch classifier loss: 0.441706; batch adversarial loss: 0.609438\n",
      "epoch 24; iter: 200; batch classifier loss: 0.461977; batch adversarial loss: 0.565252\n",
      "epoch 25; iter: 0; batch classifier loss: 0.396968; batch adversarial loss: 0.607926\n",
      "epoch 25; iter: 200; batch classifier loss: 0.431849; batch adversarial loss: 0.547727\n",
      "epoch 26; iter: 0; batch classifier loss: 0.385821; batch adversarial loss: 0.608115\n",
      "epoch 26; iter: 200; batch classifier loss: 0.457724; batch adversarial loss: 0.580168\n",
      "epoch 27; iter: 0; batch classifier loss: 0.403836; batch adversarial loss: 0.672314\n",
      "epoch 27; iter: 200; batch classifier loss: 0.462577; batch adversarial loss: 0.648739\n",
      "epoch 28; iter: 0; batch classifier loss: 0.362280; batch adversarial loss: 0.633685\n",
      "epoch 28; iter: 200; batch classifier loss: 0.372950; batch adversarial loss: 0.548664\n",
      "epoch 29; iter: 0; batch classifier loss: 0.492264; batch adversarial loss: 0.624161\n",
      "epoch 29; iter: 200; batch classifier loss: 0.432417; batch adversarial loss: 0.603874\n",
      "epoch 30; iter: 0; batch classifier loss: 0.442112; batch adversarial loss: 0.610468\n",
      "epoch 30; iter: 200; batch classifier loss: 0.382935; batch adversarial loss: 0.616535\n",
      "epoch 31; iter: 0; batch classifier loss: 0.424256; batch adversarial loss: 0.552327\n",
      "epoch 31; iter: 200; batch classifier loss: 0.354024; batch adversarial loss: 0.591538\n",
      "epoch 32; iter: 0; batch classifier loss: 0.399732; batch adversarial loss: 0.598559\n",
      "epoch 32; iter: 200; batch classifier loss: 0.381409; batch adversarial loss: 0.594655\n",
      "epoch 33; iter: 0; batch classifier loss: 0.465218; batch adversarial loss: 0.590968\n",
      "epoch 33; iter: 200; batch classifier loss: 0.502736; batch adversarial loss: 0.599420\n",
      "epoch 34; iter: 0; batch classifier loss: 0.416961; batch adversarial loss: 0.576068\n",
      "epoch 34; iter: 200; batch classifier loss: 0.380052; batch adversarial loss: 0.584869\n",
      "epoch 35; iter: 0; batch classifier loss: 0.397147; batch adversarial loss: 0.646103\n",
      "epoch 35; iter: 200; batch classifier loss: 0.395307; batch adversarial loss: 0.653069\n",
      "epoch 36; iter: 0; batch classifier loss: 0.457673; batch adversarial loss: 0.586039\n",
      "epoch 36; iter: 200; batch classifier loss: 0.443778; batch adversarial loss: 0.553954\n",
      "epoch 37; iter: 0; batch classifier loss: 0.523412; batch adversarial loss: 0.568220\n",
      "epoch 37; iter: 200; batch classifier loss: 0.482998; batch adversarial loss: 0.602485\n",
      "epoch 38; iter: 0; batch classifier loss: 0.415065; batch adversarial loss: 0.553738\n",
      "epoch 38; iter: 200; batch classifier loss: 0.425257; batch adversarial loss: 0.576283\n",
      "epoch 39; iter: 0; batch classifier loss: 0.384378; batch adversarial loss: 0.629384\n",
      "epoch 39; iter: 200; batch classifier loss: 0.491591; batch adversarial loss: 0.571779\n",
      "epoch 40; iter: 0; batch classifier loss: 0.474534; batch adversarial loss: 0.629855\n",
      "epoch 40; iter: 200; batch classifier loss: 0.401485; batch adversarial loss: 0.566332\n",
      "epoch 41; iter: 0; batch classifier loss: 0.393446; batch adversarial loss: 0.584615\n",
      "epoch 41; iter: 200; batch classifier loss: 0.429153; batch adversarial loss: 0.588341\n",
      "epoch 42; iter: 0; batch classifier loss: 0.418657; batch adversarial loss: 0.608984\n",
      "epoch 42; iter: 200; batch classifier loss: 0.420420; batch adversarial loss: 0.595763\n",
      "epoch 43; iter: 0; batch classifier loss: 0.412293; batch adversarial loss: 0.655733\n",
      "epoch 43; iter: 200; batch classifier loss: 0.325076; batch adversarial loss: 0.596317\n",
      "epoch 44; iter: 0; batch classifier loss: 0.428098; batch adversarial loss: 0.557764\n",
      "epoch 44; iter: 200; batch classifier loss: 0.456574; batch adversarial loss: 0.604061\n",
      "epoch 45; iter: 0; batch classifier loss: 0.518632; batch adversarial loss: 0.638244\n",
      "epoch 45; iter: 200; batch classifier loss: 0.454785; batch adversarial loss: 0.606444\n",
      "epoch 46; iter: 0; batch classifier loss: 0.500095; batch adversarial loss: 0.583535\n",
      "epoch 46; iter: 200; batch classifier loss: 0.409763; batch adversarial loss: 0.648253\n",
      "epoch 47; iter: 0; batch classifier loss: 0.517451; batch adversarial loss: 0.578516\n",
      "epoch 47; iter: 200; batch classifier loss: 0.514067; batch adversarial loss: 0.642272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48; iter: 0; batch classifier loss: 0.360662; batch adversarial loss: 0.586437\n",
      "epoch 48; iter: 200; batch classifier loss: 0.434596; batch adversarial loss: 0.598391\n",
      "epoch 49; iter: 0; batch classifier loss: 0.420739; batch adversarial loss: 0.603805\n",
      "epoch 49; iter: 200; batch classifier loss: 0.416696; batch adversarial loss: 0.609185\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<algorithm.adversarial_debiasing.AdversarialDebiasing at 0x7fb0743848d0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debiased_model.fit(df_orig_train, protected_attribute_names, label_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습된 Debiased Model을 Test Data에 적용\n",
    "df_pred_train_debiased = debiased_model.predict(df_orig_train, label_name)\n",
    "df_pred_test_debiased = debiased_model.predict(df_orig_test, label_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fairness Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debiasing 전후 Dataset과 Model 성능 비교를 위한 Metric 측정\n",
    "dataset_metric_train_without_debias = DatasetMetric(df_orig_train, 'sex', label_name)\n",
    "dataset_metric_test_without_debias = DatasetMetric(df_orig_test, 'sex', label_name)\n",
    "classified_metric_train_without_debias = ClassificationMetric(df_orig_train, df_pred_train_nodebiased, 'sex', label_name)\n",
    "classified_metric_test_without_debias = ClassificationMetric(df_orig_test, df_pred_test_nodebiased, 'sex', label_name)\n",
    "\n",
    "dataset_metric_train_with_debias = DatasetMetric(df_pred_train_debiased, 'sex', label_name)\n",
    "dataset_metric_test_with_debias = DatasetMetric(df_pred_test_debiased, 'sex', label_name)\n",
    "classified_metric_train_with_debias = ClassificationMetric(df_orig_train, df_pred_train_debiased, 'sex', label_name)\n",
    "classified_metric_test_with_debias = ClassificationMetric(df_orig_test, df_pred_test_debiased, 'sex', label_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_metric(met):\n",
    "    print('Accuracy: ', met.accuracy())\n",
    "    print('Balanced Accuray: ', met.balanced_accuracy())\n",
    "    print('Disparate Impact: ', met.disparate_impact())\n",
    "    print('Equal Opportunity Difference: ', met.equal_opportunity_difference())\n",
    "    print('Average Odds Difference: ', met.average_odds_difference())\n",
    "    print('Theil Index: ', met.theil_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Dataset Metric - Original Dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set: Mean Difference between Unprivileged and Privileged Group = -0.197623\n",
      " Test Set: Mean Difference between Unprivileged and Privileged Group = -0.187302\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Dataset Metric - Debiased Dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set: Mean Difference between Unprivileged and Privileged Group = -0.086453\n",
      " Test Set: Mean Difference between Unprivileged and Privileged Group = -0.097511\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Classification Metric - Plain Model - Test Dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8028390090766396\n",
      "Balanced Accuray:  0.6698333445585645\n",
      "Disparate Impact:  0.0\n",
      "Equal Opportunity Difference:  -0.4943820224719101\n",
      "Average Odds Difference:  -0.3092968918636131\n",
      "Theil Index:  0.17231994300259793\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Classification Metric - Debiased Model - Test Dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7961509588480175\n",
      "Balanced Accuray:  0.6761564882032738\n",
      "Disparate Impact:  0.5379725700573138\n",
      "Equal Opportunity Difference:  -0.08297344167676807\n",
      "Average Odds Difference:  -0.0535387400338686\n",
      "Theil Index:  0.16794294077661986\n"
     ]
    }
   ],
   "source": [
    "display(Markdown('#### Dataset Metric - Original Dataset'))\n",
    "print('Train Set: Mean Difference between Unprivileged and Privileged Group = %f'%dataset_metric_train_without_debias.mean_difference())\n",
    "print(' Test Set: Mean Difference between Unprivileged and Privileged Group = %f'%dataset_metric_test_without_debias.mean_difference())\n",
    "\n",
    "display(Markdown('#### Dataset Metric - Debiased Dataset'))\n",
    "print('Train Set: Mean Difference between Unprivileged and Privileged Group = %f'%dataset_metric_train_with_debias.mean_difference())\n",
    "print(' Test Set: Mean Difference between Unprivileged and Privileged Group = %f'%dataset_metric_test_with_debias.mean_difference())\n",
    "\n",
    "display(Markdown('#### Classification Metric - Plain Model - Test Dataset'))\n",
    "explain_metric(classified_metric_test_without_debias)\n",
    "\n",
    "display(Markdown('#### Classification Metric - Debiased Model - Test Dataset'))\n",
    "explain_metric(classified_metric_test_with_debias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:\n",
    "\n",
    "1. B. H. Zhang, B. Lemoine, and M. Mitchell, \"Mitigating UnwantedBiases with Adversarial Learning,\" \n",
    "AAAI/ACM Conference on Artificial Intelligence, Ethics, and Society, 2018.\n",
    "\n",
    "2. https://github.com/Trusted-AI/AIF360/blob/master/examples/demo_adversarial_debiasing.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf1_gpu",
   "language": "python",
   "name": "tf1_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
